{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "某班主任为了了解本班同学的数学和其他科目考试成绩间关系，在某次阶段性测试中，他在全班学生中随机抽取1个容量为5的样本进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该样本中5位同学的数学和其他科目成绩对应如下表：\n",
    "\n",
    "\n",
    "学生编号\t|1\t| 2 | 3\t| 4\t| 5\n",
    "-- | -- | -- | -- | -- | -- |\n",
    "数学分数m\t| 89\t| 91\t| 93\t| 95 | 97\n",
    "物理分数p\t| 87\t| 89\t| 89\t| 92 | 93\n",
    "语文分数c\t| 72\t| 76\t| 74\t| 71 | 76\n",
    "英语分数e\t| 83\t| 88\t| 82\t| 91 | 89\n",
    "化学分数ch\t| 90\t| 93\t| 91\t| 89 | 94\n",
    "\n",
    "利用以上数据，建立m与其他变量的多元线性回归方程，并回答下列问题：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在线性回归中，利用梯度下降法，令参数向量θ^0初始值全为0，学习率α为1，算出经过第一次迭代后的参数向量θ^1；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prameter:  [  93.  8376.  6864.6 8059.8 8501.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = np.array([[1,87,72,83,90],[1,89,76,88,93],[1,89,74,82,91],[1,92,71,91,89],[1,93,76,89,94]])\n",
    "result = np.array([89,91,93,95,97])\n",
    "\n",
    "prameter = np.array([0.0]*5)\n",
    "learnrate = 1\n",
    "newprameter = np.array([0.0]*5)\n",
    "\n",
    "J = []\n",
    "for time in range(1):\n",
    "    Jtmp, Jdertmp = 0, [0]*5\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            Jdertmp[i] += (np.dot(train[j],prameter.T) - result[j])*train[j][i]/5\n",
    "        newprameter[i] = prameter[i] - learnrate*Jdertmp[i]\n",
    "        Jtmp += (np.dot(train[j],prameter.T) - result[j])**2/(2*5)\n",
    "    J.append(Jtmp)\n",
    "    prameter = np.array(newprameter)\n",
    "J = np.array(J)\n",
    "print(\"prameter: \", prameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - \t讨论（1）中所算出的θ^1是否可以使线性回归中的代价函数J(θ)下降，即J(θ^1 )<J(θ^0 )；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J0:  4704.5 J1:  3968209318612.5\n"
     ]
    }
   ],
   "source": [
    "J = [J[0]]\n",
    "for time in range(1):\n",
    "    Jtmp, Jdertmp = 0, [0]*5\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            Jdertmp[i] += (np.dot(train[j],prameter.T) - result[j])*train[j][i]/5\n",
    "        newprameter[i] = prameter[i] - learnrate*Jdertmp[i]\n",
    "        Jtmp += (np.dot(train[j],prameter.T) - result[j])**2/(2*5)\n",
    "    J.append(Jtmp)\n",
    "    prameter = np.array(newprameter)\n",
    "J = np.array(J)\n",
    "print(\"J0: \", J[0], \"J1: \", J[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - \t讨论是否可以选取更佳的学习率α，经过第一次迭代后，使代价函数J(θ)下降得更快；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = np.array([[1,87,72,83,90],[1,89,76,88,93],[1,89,74,82,91],[1,92,71,91,89],[1,93,76,89,94]])\n",
    "result = np.array([89,91,93,95,97])\n",
    "\n",
    "prameter = np.array([0.0]*5)\n",
    "learnrate = 0.00001\n",
    "newprameter = np.array([0.0]*5)\n",
    "\n",
    "J = []\n",
    "for time in range(40):\n",
    "    Jtmp, Jdertmp = 0, [0]*5\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            Jdertmp[i] += (np.dot(train[j],prameter.T) - result[j])*train[j][i]/5\n",
    "        newprameter[i] = prameter[i] - learnrate*Jdertmp[i]\n",
    "        Jtmp += (np.dot(train[j],prameter.T) - result[j])**2/(2*5)\n",
    "    J.append(Jtmp)\n",
    "    prameter = np.array(newprameter)\n",
    "J = np.array(J)\n",
    "\n",
    "plt.scatter(np.arange(40), J[:40])\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 利用标准方程求出最优的多元线性回归方程（系数精确到0.01），并预测该班物理分数88、语文分数73、英语分数87、化学分数92同学的数学分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prameter:  [[-19.5      1.6875   0.375   -0.3125  -0.4375]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = np.mat([[1,87,72,83,90],[1,89,76,88,93],[1,89,74,82,91],[1,92,71,91,89],[1,93,76,89,94]])\n",
    "result = np.mat([89,91,93,95,97])\n",
    "\n",
    "prameter = (train.T*train).I * (train.T*result.T)\n",
    "print(\"prameter: \", prameter.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testresult:  [[88.9375]]\n"
     ]
    }
   ],
   "source": [
    "testdata = np.mat([1,88,73,87,92])\n",
    "testresult = prameter.T*testdata.T\n",
    "print(\"testresult: \", testresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - \t在L2正则化线性回归中，令正则化平衡系数λ为1，利用标准方程求出最优的L2正则化多元线性回归方程（系数精确到0.01），并比较其与（4）中得出的多元线性回归方程对数学分数的预测，哪个更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = np.mat([[1,87,72,83,90],[1,89,76,88,93],[1,89,74,82,91],[1,92,71,91,89],[1,93,76,89,94]])\n",
    "result = np.mat([89,91,93,95,97])\n",
    "\n",
    "eye = np.eyes()\n",
    "prameter = (train.T*train + ).I * (train.T*result.T)\n",
    "print(\"prameter: \", prameter.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
